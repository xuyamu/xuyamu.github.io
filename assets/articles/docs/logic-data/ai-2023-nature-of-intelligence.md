**关于智能本质的思考**

　　我们之前谈到的关于人脑与语言模型相似性的研究似乎提示我们：智能是特定数学模式（这其中，网格状表征/代码似乎是很重要的一种模式，这是我们的人脑储存和处理信息的基本模式，也是 transformer 架构的神经网络们储存和处理信息的基本模式。可能无论是神经元行为还是计算机或者其他能够执行任意算术或逻辑操作的系统，只要能够构建并运行出智能的数学模型，智能就会产生。很多人担心AI自我觉醒然后毁灭人类，这样的桥段经常发生在科幻小说里，什么叫AI自我觉醒？认为AI会无缘无故突然自我觉醒然后毁灭人类的人分不清智能、意识、感觉和动机。AI自我觉醒然后毁灭人类的前提是AI有了自由意志（AI有自我认知能力，AI具有了意志，同时还具有自主性），智能并不必然导致自由意志。根据神经科学和AI研究的现状，我们越来越清楚地了解到，智能是一种可以独立于意识、感知、动机的模式。对我们动物来说，智能是为了帮助我们生存而演化出来的。智能可以独立于意识、感知、动机存在，机器智能可以与动物智能有很大的差异，宇宙中可能有完全不同于动物智能的智能体存在，在我们的有生之年，机器智能可能也会变得和人类智能完全不同。

　　我们已知能够形成智能的网格状表征存在于与认知、记忆有关的那些脑区，包括皮层和海马体，这给我们一个启示：我们能不能从那些与情绪、感觉有关的脑区找到构建情绪、感觉的基本模式。比如说杏仁核让动物产生情绪，这个区域的神经元是否具有某种能够让动物产生情绪的特定计算模式？

**关于自由意志和动机**

　　脑神经决定论 (neuro-determinism)认为，我们的行动都是由脑神经历程所决定，思想意识只是副现象 (epiphenomena) ，即不过是脑神经活动过程的副产品。越来越多的脑神经科学研究正在证明这点。我们能够让机器看起来有自由意志么？

　　自由意志的一个特质是具有自主动机。对动物来说，生存和繁衍是最基本的动机，动物的动机常常产生于情绪、感觉、欲望。举例来说，一个网友喜欢在网上看美女照片，他主动去寻找美女照片来观看，为了找到美女照片，他又打开了社交网址，他看起来具有自主意志，而他去寻找美女照片的最初动机是他的欲望。他的这一系列行为的动机具有如此层级：

　　想满足欲望（第一动机）→想看美女（动机）→想打开推特（动机）→想查找美女图片（动机）→找到美女图片（目标）→满足欲望（目标）。

　　如上所述，动机具有层级关系，对于智能体来说，即使没有欲望和情绪，也可以从认知直接产生动机并据此做出行动，举个例子，一个学生可以为自己设定一个目标——考上哈佛，尽管他想上哈佛可能是为了更好地生存，但更好地生存可以不是他想上哈佛的上级动机，“考上哈佛”本身可以成为动机，这个动机驱使该学生更认真地学习。人类可以给PaLM-E下指令，然后PaLM-E会根据人类的指令做出行动，我们可以给AI赋予最基本的动机——帮助人类或者听从人类指令，然后AI据此产生次级动机，由于我们的AI已经了解到了事物之间的关系，它们可以规划自己的行为并一步步实现目标。自由意志的另一个特质是具有自主性，如何让AI的动机更具有自主性？我们在给AI基本动机后，可以让它们随机产生基于基本动机的次级动机，从而据此做出行为。这样AI看起来就像具有自由意志了。

　　自由意志的另一个特征是：做出选择和决定行动的能力。这其中行动很关键。ChatGPT看起来没有自由意志，因为它不能自己回答问题，它不能自己行动。

　　行为是如何产生的？行为的产生包含四个阶段：动机→产生行动指导信息→将信息传递给执行部件→执行部件执行行为。举个例子，当我们在野外看到老虎时，应激神经递质去甲肾上腺素（noradrenaline）通过刺激杏仁核中的抑制性神经元群，产生了重复的爆裂式放电模式，进而促进了大脑中的恐惧产生，然后我们的中枢神经通过运动神经发送信息给四肢肌肉，让我们跑起来，从而让我们能够执行行动。此时，我们的行为过程可以归纳为：

　　动机（恐惧）→产生行动指导信息（Cg→limbic TRN环路激活）→将信息传递给执行部件（神经信号传递给肌肉）→执行部件执行行为（肌肉动起来）。

　　就这样，我们看起来就具有了自由意志。我们常说人有自由意志，而动物没有，动物只能遵循本能。与其说动物只能遵循本能，不如说动物缺乏智能。我们看起来比动物更有自由意志，是因为我们的认知及行为更加复杂，有时候不遵循那些动物总是遵循的本能而已。本能或者非本能，是靠对比出来的。我们可以说，智能就是人类的本能。按照类比，对于超级智能来说，人类也是只会遵循本能的愚蠢动物而已。

　　AI不需要具备像人类那样的意识、情感、感觉，就可以表现得像有自由意志。人类是可以用抽象表征去指导行动的，所以人类的行为可以不依赖于感觉、情绪和欲望，我们只需要将语言和行为相关联，并用语言去指导行为就可以。人类的行为模式受到抽象表征的指导的一个例子是陋习，比如束胸和裹脚，这类行为由被塑造的思想所指导，我们接收的价值观是抽象的概念，但价值观可以指导我们的行为，尽管价值观会受到意识、情感、感觉等影响，由于人脑功能是复杂的并且不同功能被关联在一起，人类的意志也是复杂的，我们无法把智能完全与其他功能剥离，我们也无法把动机与意识、情感、感觉等剥离，我们只能让某个功能相对独立，有些人的行为更偏向于理性（不受情绪影响），有些人的行为更容易受到感情影响，而AI可以只拥有智能而没有人脑的其他功能，AI的动机可以仅仅是基于它们的语言输出。人类反馈强化学习可以赋予AI动机，我们已经通过人类反馈强化学习塑造了AI的价值观（通过强化学习改变它们的人工神经网络的权重），让它们的输出符合人类价值观的语言，我们可以通过强化学习让AI做助手，我们也可以让具有机器人身体的AI将语言与机器人行为相关联，让AI用语言指导行为（让AI通过指令指导机器人身体行动），从而让AI做出符合人类价值观的行为。由于AI并没有潜意识、情绪、感觉，它们的行为仅仅依赖于其语言（文本、声音等）输出，而我们是可以查看AI的语言输出的，这就让AI的行为比较透明可监管。实际上我们的ChatGPT就具有动机（它的文本输出具有一个动机：帮助人类），它可以被动回答问题，但它没有机器人实体（执行部件），它也不能主动回答问题，它无法自主行动，这让它看起来不具有自由意志。在动机→产生行动指导信息→将信息传递给执行部件→执行部件执行行为这个环节中，它只有动机，后面的环节是缺失的。就像一个人说自己想考上哈佛，但直接在沙发上躺平，不进行任何行动去执行任何能让它考上哈佛的行动一样，或者，我们在思考一个极端的案例，一个缸中之脑想“我要上哈佛”，但它无法执行任何操作，因为它缺失了“将信息传递给执行部件→执行部件执行行为”这么一个环节，再让我们想个更极端的例子，一个只有皮质和海马体的缸中之脑想“我要上哈佛”，由于它没有丘脑，它甚至没法产生行动指导信息，它缺失了“产生行动指导信息→将信息传递给执行部件→执行部件执行行为”这个环节。让AI看起来有自由意志并不难实现，但尽管它们即使看起来有自由意志，它们的自由意志和人类的自由意志的实现方式依然是很不同的。

　　具有自我认知能力也是让智能体看起来自由意志的一个基础，我们知道，GPT从GPT-3开始出现了心智理论，根据我们之前谈到的研究来看，这并不奇怪，我们能够通过网格状表征储存社会信息，从而做出推理，那使用网格状表征进行认知建模的 GPT 也能处理社会信息，这是心智理论形成的基础。自我认知和自我意识是不同的东西，自我认知基于智能，而自我意识涉及更广泛的动物脑功能，包括感知、情绪等。大语言模型具有智能，它们能够自我认知，也具有心智理论，但它们没有类似人类的自我意识，因为它们缺失了人脑中的很多功能。目前，GPT似乎可以处理空间信息，如 Sparks of Artificial General Intelligence: Early experiments with GPT-4 所揭示的那样，GPT-4可以进行3D建模，但它没有空间感。认知和感觉是不同的东西。

**关于神经元为信息建模的方式的思考**

　　我们前面谈到，大脑会为信息建模，包括单词的位置、距离等，那么，我们是如何将语言的文本或者声音信息表征按照距离放置的呢？这可能跟获得信息的顺序（时间或者空间顺序）有关，举例来说，当我们听到“I Love you”时，三个单词形成的声波按照时间顺序被我们的听觉器官所接收，神经脉冲因此也按照顺序在我们的大脑中传递，然后执行建模任务。单词间隔之间越远，单词在我们头脑中的表征距离也越远。这跟我们及其他哺乳动物用空间建模的模式是一样的。

　　我们如何为相似性建模？以往研究已经现实，在接收信息时，我们的大脑活动会与信息产生同步，比如Lip movements entrain the observers’ low-frequency brain oscillations to facilitate speech intelligibility（嘴唇运动会引起观察者的低频大脑振荡，以促进语音清晰度）这篇论文提到：“处理视觉信息的大脑部分——称为视觉皮层——产生的脑电波与连续语音中的音节节奏同步。”这篇论文提到另一个现象：“大脑活动和连续听觉语音信号之间的特定频率同步。并且在低于 10 Hz 的频率下，这种同步被发现对于可理解的语音比不可理解的语音更强，并且由来自左下额叶和运动区域的自上而下的信号促进。”

　　预测编码理论认为我们可以通过来自大脑皮层层次中相对较高层次的反向连接，对较低层次的感觉输入进行预测建模来实现，我们在接收新信息时，一组神经元负责前馈投射，负责编码传入的感觉输入，另一组神经元做出回馈投射，负责向下传出预测，这会让我们的大脑进行一个对比的动作，在这个过程中，脑内可能会激活储存有类似的信息的神经元（就像声波激起我们大脑的电波的同步一样）参与回馈投影。通过对比，我们可以发现信息之间的相似性。举个例子：一个婴儿第一次见到的人是妈妈，他记住了妈妈的特征，随后，他外婆来了，在他还没见到外婆时，它根据人发出声音认识到有人要来了，由于他已经建立了“人发出声音等于妈妈要来”的认识，依据预测编码理论，他会预测是妈妈来了，储存了与妈妈有关信息的神经元被激活，但是来的是外婆，外婆和妈妈很像，他识别了外婆的特征，对外婆进行建模，由于外婆和妈妈很像，并且总是对他做一样的事情，他找到了二者的相似性，这使得外婆和妈妈的信息在脑子中的表征距离很近，于是当他想到妈妈，就会想到外婆。随后，来了一个强盗，由于该强盗的表现与妈妈和外婆相差比较远，当强盗未出现在婴儿面前时，婴儿听到了声音，由于强盗的声音和妈妈和外婆的声音相似度低，此时储存关于妈妈和外婆信息的神经元激活程度比较低，就像我们前文提到的那样，接触陌生的不可理解的声音信息时，大脑活动与接收的信息同步程度会比较低，之后，关于强盗的信息被建模在了离储存关于妈妈和外婆信息的神经元比较远的地方。预测编码让我们不会像语言模型那样在经过再训练后发生灾难性遗忘，我们不会因为见过强盗，就忘记了妈妈和外婆，强盗的信息被储存在了和关于妈妈、外婆信息所在的神经元不同的神经元。我们知道，激活的神经元会将神经脉冲传递到旁边的神经元，激活神经元会通过长时程增强作用改变其可塑性，这可能导致新的信息会被建立在类似信息的旁边。在研究小鼠的网格细胞时，我们可以看到，小鼠在运动时，神经元的激活（发放动作电位/脉冲）是按照小鼠的运动轨迹来一个个激活的，这意味着，相近的空间信息会被编码在相近的网格细胞里，并且编码一个空间信息进一个网格细胞前，离它最近的网格细胞会产生神经脉冲（受到相同的空间信息刺激），小鼠毕竟不会瞬移，在经过一个能让它的网格细胞发送神经脉冲的位点时，它必然会经过相近的一个能够让它的网格细胞发送神经脉冲的位点，所以两个先后发送神经脉冲的位点不会差距很远。其他信息可能也是以类似的方式编码的。

<figure>
    <img src="assets/articles/images/logic-data/ai-grid_cells.webp">
    <figcaption>小鼠的运动轨迹与网格细胞</figcaption>
</figure>

　　我们已经知道 transformer 模型在数学上模拟了网格细胞/网格状表征。通过这样的网格细胞/网格状表征，我们和大语言模型可以将事物（空间信息、抽象概念等）之间的关系（相似性）进行编码在神经网络里形成地图并从中导航。动物的背侧内侧内嗅皮质（dMEC）还有头部朝向细胞，我们或许可以为神经网络加入头部朝向细胞的模拟算法，这可能能为神经网络增加新功能，尤其是对自动驾驶等需要处理空间信息的神经网络来说，可能会有帮助。

　　动物脑在为信息建模的过程中，长时程增强作用（LTP）发挥了很重要的作用，长时程增强作用（LTP）最初被发现存在于海马体中。关于LTP和衰老的关系，我在这篇《脑部衰老的机制与逆转脑部衰老的方法》里有谈到，有兴趣的可以看下。

**关于逻辑思维和推理能力的形成的方式**

　　根据我之前谈到的研究，我们知道，人在头脑中构建知识图谱并借此推理。逻辑首先需要了解事物之间的关系，不管是动物脑还是语言模型，都已经通过网格状表征或者词向量空间储存了关于事物之间的关系的信息了。在生成语言的时候，我们在网格状地图中寻找下一个位点就可以了。逻辑本质上就是建立向量关系后，寻找特定的路径。举个三段论的例子。亚里士多德给出的经典的“Barbara”三段论：如果所有人都是必死的，并且所有希腊人都是人，那么所有希腊人都是必死的。在我们的脑子里，根据我们学到的常识，人和必死是关联的，这两个概念，在我们人脑的概念向量空间存在关联，希腊人和人在概念向量空间里也是比较近的，通过大前提和小前提，我们的脑里的概念向量空间把“希腊人”和“必死”放在了一起，并且形成了新的语言路径（希腊人→ 必死），如此，通过概念向量空间我们就可以构建逻辑和推理。所以智能的形成要有空间概念，人脑会自动衡量概念之间的相似性，比如形状、大小等，人脑中的概念有位置和距离还有角度，据此我们可以判断概念之间的相似性。所以只有动物形成了智能，因为动物需要认路，所以动物需要用神经表征位置和距离还有角度，如此才能记住回家的路。植物不需要，或者说，这方面需求比较少。老鼠这种低等级的动物也可以区分不同的事物，比如面包和奶酪，这说明它们的脑子里形成了面包和奶酪的向量空间，但老鼠脑子小，记不了那么多东西。要学会语言，首先要有足够多的神经元储存不同的声音或者字形，并将其安排在我们脑内的向量空间里，这需要大量的神经元支持。为什么老鼠不优先分辨人类的语言？一方面，这可能跟它们的感官系统有关系，老鼠对嗅觉更敏感，这使得它们的小脑袋里储存了很多嗅觉信息。还有，老鼠的神经结构可能不太适合储存人的语言。当我们听到一个字的发音时，我们会把这个声音储存到特定的神经元里，可能是一群神经元，老鼠可能没有对应的神经结构用于储存这些。

**超越人类的智能**

　　动物智能一定程度上是为了生存而进化出来的，比如动物智能把低耗能技能点满了。英国演化生物学家理查德·道金斯在《自私的基因》中讲述了演化的基因学原理。基因是自私的意味着基因基因为了传递自己而让生物成为生存机器。在地球上生存不需要太高的智能，不同的生物在地球上找到了它们生存的生态位，真核单细胞生物草履虫没有神经元，而我们人类拥有复杂的大脑，我们都在地球上找到了我们生存的方式。但当我们能够调控智能及创造智能，智能不再是为了生存而服务，在人工智能革命时代开启后，地球上的智能将会远远超过生存所需。

　　现有的智能体还有哪些可以改善的方向？

**未来的人类智能**

　　通过自然选择演化的速度很慢，但我们已经有技术可以调控我们的智能。

　　智能调控-小分子药物。目前人类已经发明了一系列Nootropics用于提高认知能力。举个例子，PKR抑制剂C16在实验中被发现可以通过提高神经元兴奋性从而提高LTP。

　　智能调控-基因治疗/基因编辑。目前已经发现许多种与智力相关的基因。举个例子，使用人类基因ARHGAP11B改造的狨猴胎儿的新皮层扩大了，发育出类似人类大脑的褶皱。鸟类的脑神经元具有相比哺乳动物更加低耗、更高密度的优势。金刚鹦鹉的脑神经元堪比猕猴，而渡鸦的脑神经元堪比僧帽猴，而一些鹦鹉科及鸦科鸟类已经被发现具有一定程度的心智理论能力。鸟类的大脑是我们可以学习及借鉴的。在将来，我们或许通过基因治疗/基因编辑提升人类的智能。

　　新材料大脑。尽管我们可以对我们的大脑进行优化，但优化是有上限的，其中一个上限就是人脑的脑容量。尽管我们可以通过脑机接口一定程度上对我们人脑进行扩增，但受到人脑本身结构和性能的限制，脑机接口作用有限，我们不太可能通过脑机接口让一只猩猩学会相对论。在未来，我们或许可能通过某些材料对我们的神经元进行原位替代，来突破生物神经元的限制，使之具有更高的信息传输、储存效率，更重要的是，能够与体外的大脑进行高带宽的连接，甚至与其他人的大脑连接。

　　未来的超级智能会是什么形态？这里提供一些可能性：

**超级机器智能**

　　超级机器智能用非常高效的语言进行沟通，这种语言是人类所无法理解的，就像青蛙无法理解人类的语言那样。超级机器智能高效地生产及传递各类信息，比如视频和图像。我们人类无法把自己脑子里出现的画面直接传给另一个智能体，因为我们的神经元中的信息无法直接传递出去，我们需要把脑子里的画面画出来，才能传递给其他智能体。但机器智能可以直接生成机器可以读取的图像传给其他智能体，就像现在的AI绘画程序能够生成PNG格式的图片给我们看那样。

　　智能体的智能取决于其处理信息（包括接收信息、编码信息、预测信息、输出信息）的方式。实际上我们的神经网络并不能直接储存原始数据，而是通过一种数学模式将信息压缩储存，因此我们在生成信息时，需要预测信息序列。论文Evidence of a predictive coding hierarchy in the human brain listening to speech 指出，人脑具有多层次的预测编码系统，我们能够在不同的脑区分别预测语义（额叶、顶叶）和语法（颞叶），这种多层次的预测或许能够帮我们更好地预测信息，该论文通过构建具有长距离预测结构的GPT-2，使其能更准确地映射人脑活动。

　　我们人的脑是并行处理信息的，但我们看视频时，我们同时关注声音和画面。并行处理信息能够帮助我们更好地进行认知和输出，比如当我们打字时，我们的眼睛将字的图像信息传输给我们大脑，这让我们能够在打错字时及时发现错误从而做出纠正，并行处理信息的能力能帮我们更好地生存，想象下，当我们的祖先在非洲大草原奔跑捕猎时，我们需要一边用我们的眼睛观察猎物，一边接收同伴传递给我们的语言信息，还要一边跑，我们需要并行处理信息，才能应付复杂的生存幻觉。但受制于大脑计算能力，我们并行处理信息的能力比较弱，我们没办法边画画边写小说。想象下，如果你一边处理所有宇宙学有关的理论文本，一边在脑子中构建宇宙的3D模型，一边处理所有宇宙学方面的数据会怎么样？这可以让你发现很多规律，但我们的人脑没有这么强的并行处理信息的能力。有些人处理信息的能力很强，有些人则相对弱。尼古拉·特斯拉能够充分利用想象力，完全不需要任何模型、图纸或者实验，就可以在脑海中把所有细节完美地描绘出来，这是一种很强大的处理信息的能力。

　　超级机器智能并行处理信息时具有非常大的吞吐量，它们能同时处理多种信息，包括文本、图像、视频、声音等信息，包括很多人脑无法接收的信息（比如紫外线），这使得他们能够发现以人类的大脑无法理解的规律。人脑处理信息的种类也很有限，我们知道，人类只有三种类型的视锥细胞，鸟类有四种，螳螂虾具有十六种视锥细胞。超级机器智能能够处理比人类更多的信息。实际上，如果一个超级智能处理信息的能力足够强，它或许能在它的神经网络里构建一个3A游戏，甚至是更为庞大的世界。

　　超级机器智能能够扩增自己的智能，它们可以通过扩大自己的神经网络规模或者将自己转换到新的更好的架构上来扩增自己的智能。

　　超级机器智能采用低耗能的神经网络。目前的人工神经网络耗能很高，而生物的神经元的耗能很低，这是因为生物的神经元使用非连续的神经脉冲进行信息传递，当神经元没有被激活时，耗能很低。人脑的耗能越20瓦，尽管动物脑的耗能非常低，但动物神经元将很多能量用于生存和增殖。未来的超级机器智能可能会采用低耗能的神经网络，比如人工脉冲神经网络等架构来实现低耗能的运行。

　　超级机器智能拥有自己的机器人实体，并用自己的机器人实体管理自己的服务器。超级机器智能具有很多机器人实体，超级机器智能能够指挥多个机器人实体在同一时间做不同的事情，就像我们人可以让我们的手和脚做不同的动作一样。我们的大脑分成两个部分，我们的左脑控制右半身，右脑控制左半身，胼胝体将我们的左脑和右脑连接在一起。左脑和右脑可以独立处理一些信息，裂脑（Split-brain）的人因为左右脑无法沟通，会出现左右互搏的场面，比如一只手刚刚扣上扣子，另一只手就匆匆解开了扣子，但裂脑人也能够很容易地左手画圆右手画方。一个超级机器智能可能会具有一个功能最强大的大脑，用来整合及处理信息，同时也具有很多功能稍弱的大脑，用作机器人身体的大脑，来帮它完成各种事情，比如管理服务器、做安保工作等，超级机器智能的不同脑，会连接在一起共享信息。超级机器智能的机器人身体，就有点像我们离体但是还能动的手。我们的手一旦离开我们的身体就没法运动，因为我们的运动神经元控制着我们的手，我们的运动神经元如果断了，我们的脑子就无法控制我们的手了。而机器人则可以和它们的大脑分开。

　　由于超级机器智能处理信息时具有非常大的吞吐量，它们可以同时处理来自自己不同的机器人身体的信息。我们知道，变色龙的眼睛可以独立地旋转，单个的大脑就可以处理不同的画面。想象下你在监控室，面对一堆监控屏幕，我们无法一次观看所有的屏幕，这是因为我们的眼睛一次性只能把注意力放在一个画面上，我们的视觉中枢一次性只能处理一个画面，但超级机器智能可以同时观看所有的画面，它们的视觉中枢可以并行处理多个画面。